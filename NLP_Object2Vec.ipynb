{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 918kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Requirement already up-to-date: singledispatch in /usr/lib/python2.7/dist-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
      "Successfully built nltk\n",
      "Installing collected packages: six, nltk\n",
      "  Found existing installation: six 1.10.0\n",
      "    Uninstalling six-1.10.0:\n",
      "      Successfully uninstalled six-1.10.0\n",
      "Successfully installed nltk-3.4 six-1.12.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting jsonlines\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonlines) (1.11.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-1.2.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install -U nltk\n",
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNLI_PATH = 'snli_1.0'\n",
    "#STS_PATH = 'sts2016-english-with-gs-v1.0'\n",
    "\n",
    "if not os.path.exists(SNLI_PATH):\n",
    "    url_address = \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
    "    request = requests.get(url_address)\n",
    "    zfile = ZipFile(io.BytesIO(request.content))\n",
    "    zfile.extractall()\n",
    "    zfile.close()\n",
    "\n",
    "#if not os.path.exists(STS_PATH):\n",
    "#    url_address = \"http://alt.qcri.org/semeval2016/task1/data/uploads/sts2016-english-with-gs-v1.0.zip\"\n",
    "#    request = requests.get(url_address)\n",
    "#    zfile = ZipFile(io.BytesIO(request.content))\n",
    "#    zfile.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import sys, os\n",
    "import jsonlines\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain, islice\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "BOS_SYMBOL = \"<s>\"\n",
    "EOS_SYMBOL = \"</s>\"\n",
    "UNK_SYMBOL = \"<unk>\"\n",
    "PAD_SYMBOL = \"<pad>\"\n",
    "PAD_ID = 0\n",
    "TOKEN_SEPARATOR = \" \"\n",
    "VOCAB_SYMBOLS = [PAD_SYMBOL, UNK_SYMBOL, BOS_SYMBOL, EOS_SYMBOL]\n",
    "\n",
    " \n",
    "LABEL_DICT = {'entailment':0, 'neutral':1, 'contradiction':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Utility functions\n",
    "\n",
    "def read_jsonline(fname):\n",
    "    \"\"\"\n",
    "    Reads jsonline files and returns iterator\n",
    "    \"\"\"\n",
    "    with jsonlines.open(fname) as reader:\n",
    "        for line in reader:\n",
    "            yield line\n",
    "\n",
    "def sentence_to_integers(sentence, tokenizer, word_dict):\n",
    "    \"\"\"\n",
    "    Converts a string of tokens to a list of integers\n",
    "    TODO: Better handling of the case \n",
    "          where token is not in word_dict\n",
    "    \"\"\"\n",
    "    return [word_dict[token] for token in get_tokens(sentence, tokenizer)\n",
    "           if token in word_dict]\n",
    "\n",
    "\n",
    "def get_tokens(line, tokenizer):\n",
    "    \"\"\"\n",
    "    Yields tokens from input string.\n",
    "\n",
    "    :param line: Input string.\n",
    "    :return: Iterator over tokens.\n",
    "    \"\"\"\n",
    "    for token in tokenizer.tokenize(line):\n",
    "        if len(token) > 0:\n",
    "            yield token\n",
    "\n",
    "            \n",
    "def get_tokens_from_snli(input_dict, tokenizer):\n",
    "    iter_list = list()\n",
    "    for sentence_key in ['sentence1', 'sentence2']:\n",
    "        sentence = input_dict[sentence_key]\n",
    "        iter_list.append(get_tokens(sentence, tokenizer))\n",
    "    return chain(iter_list[0], iter_list[1])\n",
    "\n",
    "\n",
    "def get_tokens_from_sts(input_sentence_pair, tokenizer):\n",
    "    iter_list = list()\n",
    "    for s in input_sentence_pair:\n",
    "        iter_list.append(get_tokens(s, tokenizer))\n",
    "    return chain(iter_list[0], iter_list[1])\n",
    "\n",
    "\n",
    "def resolve_snli_label(raw_label):\n",
    "    \"\"\"\n",
    "    Converts raw label to integer\n",
    "    \"\"\"\n",
    "    return LABEL_DICT[raw_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data_iter, dataname='snli', num_words=50000, min_count=1, use_reserved_symbols=True, sort=True):\n",
    "    \"\"\"\n",
    "    Creates a vocabulary mapping from words to ids. Increasing integer ids are assigned by word frequency,\n",
    "    using lexical sorting as a tie breaker. The only exception to this are special symbols such as the padding symbol\n",
    "    (PAD).\n",
    "\n",
    "    :param data_iter: Sequence of sentences containing whitespace delimited tokens.\n",
    "    :param num_words: Maximum number of words in the vocabulary.\n",
    "    :param min_count: Minimum occurrences of words to be included in the vocabulary.\n",
    "    :return: word-to-id mapping.\n",
    "    \"\"\"\n",
    "    vocab_symbols_set = set(VOCAB_SYMBOLS)\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    if dataname == 'snli':\n",
    "        raw_vocab = Counter(token for line in data_iter for token in get_tokens_from_snli(line, tokenizer)\n",
    "                        if token not in vocab_symbols_set)\n",
    "    elif dataname == 'sts':\n",
    "        raw_vocab = Counter(token for line in data_iter for token in get_tokens_from_sts(line, tokenizer) \n",
    "                            if token not in vocab_symbols_set)\n",
    "    else:\n",
    "        raise NameError(f'Data name {dataname} is not recognized!')\n",
    "        \n",
    "    print(\"Initial vocabulary: {} types\".format(len(raw_vocab)))\n",
    "\n",
    "    # For words with the same count, they will be ordered reverse alphabetically.\n",
    "    # Not an issue since we only care for consistency\n",
    "    pruned_vocab = sorted(((c, w) for w, c in raw_vocab.items() if c >= min_count), reverse=True)\n",
    "    print(\"Pruned vocabulary: {} types (min frequency {})\".format(len(pruned_vocab), min_count))\n",
    "    \n",
    "    # truncate the vocabulary to fit size num_words (only includes the most frequent ones)\n",
    "    vocab = islice((w for c, w in pruned_vocab), num_words)\n",
    "\n",
    "    if sort:\n",
    "        # sort the vocabulary alphabetically\n",
    "        vocab = sorted(vocab)\n",
    "    if use_reserved_symbols:\n",
    "        vocab = chain(VOCAB_SYMBOLS, vocab)\n",
    "    \n",
    "    word_to_id = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "    print(\"Final vocabulary: {} types\".format(len(word_to_id)))\n",
    "\n",
    "    if use_reserved_symbols:\n",
    "        # Important: pad symbol becomes index 0\n",
    "        assert word_to_id[PAD_SYMBOL] == PAD_ID\n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_snli_to_integers(data_iter, word_to_id, dirname=SNLI_PATH, fname_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Go through snli jsonline file line by line and convert sentences to list of integers\n",
    "    - convert entailments to labels\n",
    "    \"\"\" \n",
    "    fname = 'snli-integer-' + fname_suffix + '.jsonl'\n",
    "    path = os.path.join(dirname, fname)\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    count = 0\n",
    "    max_seq_length = 0\n",
    "    with jsonlines.open(path, mode='w') as writer:\n",
    "        for in_dict in data_iter:\n",
    "            #in_dict = json.loads(line)\n",
    "            out_dict = dict()\n",
    "            rlabel = in_dict['gold_label']\n",
    "            if rlabel in LABEL_DICT:\n",
    "                rsentence1 = in_dict['sentence1']\n",
    "                rsentence2 = in_dict['sentence2']\n",
    "                for idx, sentence in enumerate([rsentence1, rsentence2]):\n",
    "                    #print(count, sentence)\n",
    "                    s = sentence_to_integers(sentence, tokenizer, word_to_id)\n",
    "                    out_dict[f'in{idx}'] = s\n",
    "                    count += 1\n",
    "                    max_seq_length = max(len(s), max_seq_length)\n",
    "                out_dict['label'] = resolve_snli_label(rlabel)\n",
    "                writer.write(out_dict)\n",
    "            else:\n",
    "                count += 1\n",
    "    print(f\"There are in total {count} invalid labels\")\n",
    "    print(f\"The max length of converted sequence is {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_snli_full_vocab(dirname=SNLI_PATH, force=True):\n",
    "    vocab_path = os.path.join(dirname, 'snli-vocab.json')\n",
    "    if not os.path.exists(vocab_path) or force:\n",
    "        data_iter_list = list()\n",
    "        for fname_suffix in [\"train\", \"test\", \"dev\"]:\n",
    "            fname = \"snli_1.0_\" + fname_suffix + \".jsonl\"\n",
    "            data_iter_list.append(read_jsonline(os.path.join(dirname, fname)))\n",
    "        data_iter = chain(data_iter_list[0], data_iter_list[1], data_iter_list[2])\n",
    "        with open(vocab_path, \"w\") as write_file:\n",
    "            word_to_id = build_vocab(data_iter, num_words=50000, min_count=1, use_reserved_symbols=False, sort=True)\n",
    "            json.dump(word_to_id, write_file)\n",
    "\n",
    "make_snli_full_vocab(force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_snli_data(dirname=SNLI_PATH, vocab_file='snli-vocab.json', outfile_suffix=\"\", force=True):\n",
    "    for fname_suffix in [\"train\", \"test\", \"validation\"]:\n",
    "        outpath = os.path.join(dirname, f'snli-integer-{fname_suffix}-{outfile_suffix}.jsonl')\n",
    "        if not os.path.exists(outpath) or force:\n",
    "            if fname_suffix=='validation':\n",
    "                inpath = os.path.join(dirname, f'snli_1.0_dev.jsonl')\n",
    "            else:\n",
    "                inpath = os.path.join(dirname, f'snli_1.0_{fname_suffix}.jsonl')\n",
    "            data_iter = read_jsonline(inpath)\n",
    "            vocab_path = os.path.join(dirname, vocab_file)\n",
    "            with open(vocab_path, \"r\") as f:\n",
    "                word_to_id = json.load(f)   \n",
    "            convert_snli_to_integers(data_iter, word_to_id, dirname=dirname, \n",
    "                                     fname_suffix=f'{fname_suffix}-{outfile_suffix}')\n",
    "\n",
    "            \n",
    "make_snli_data(force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43533 words in vocabulary snli_1.0/snli-vocab.json\n"
     ]
    }
   ],
   "source": [
    "def print_vocab_size(vocab_path):\n",
    "    with open(vocab_path) as f:\n",
    "        word_to_id = json.load(f)\n",
    "        print(f\"There are {len(word_to_id.keys())} words in vocabulary {vocab_path}\")\n",
    "    \n",
    "\n",
    "vocab_path = os.path.join(SNLI_PATH, 'snli-vocab.json')\n",
    "print_vocab_size(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define hyperparameters and define S3 input path\n",
    "DEFAULT_HP = {\n",
    "  \"enc_dim\": 4096,\n",
    "  \"mlp_dim\": 512,\n",
    "  \"mlp_activation\": \"linear\",\n",
    "  \"mlp_layers\": 2,\n",
    "  \"output_layer\" : \"softmax\",\n",
    "\n",
    "  \"optimizer\" : \"adam\",\n",
    "  \"learning_rate\" : 0.0004,\n",
    "  \"mini_batch_size\": 32,\n",
    "  \"epochs\" : 20,\n",
    "  \"bucket_width\": 0,\n",
    "\n",
    "  \"early_stopping_tolerance\" : 0.01,\n",
    "  \"early_stopping_patience\" : 3,\n",
    "\n",
    "  \"dropout\": 0,\n",
    "  \"weight_decay\": 0,\n",
    "\n",
    "  \"enc0_max_seq_len\": 82,\n",
    "  \"enc1_max_seq_len\": 82,\n",
    "\n",
    "  \"enc0_network\": \"hcnn\",\n",
    "  \"enc1_network\": \"enc0\",\n",
    "\n",
    "  \"enc0_token_embedding_dim\": 300,\n",
    "  \"enc0_layers\": \"auto\",\n",
    "  \"enc0_cnn_filter_width\": 3,\n",
    "\n",
    "  \"enc1_token_embedding_dim\": 300,\n",
    "  \"enc1_layers\": \"auto\",\n",
    "  \"enc1_cnn_filter_width\": 3,\n",
    "\n",
    "  \"enc0_vocab_file\" : \"\",\n",
    "  \"enc1_vocab_file\" : \"\",\n",
    "\n",
    "  \"enc0_vocab_size\" : 43533,\n",
    "  \"enc1_vocab_size\" : 43533,\n",
    "\n",
    "  \"num_classes\": 3,\n",
    "\n",
    "  \"_num_gpus\" : \"auto\",\n",
    "  \"_num_kv_servers\" : \"auto\",\n",
    "  \"_kvstore\" : \"device\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path for training is s3://aws-ml-chicago-team-bravesouls/object2vec/input/\n",
      "Trained model will be saved at s3://aws-ml-chicago-team-bravesouls/object2vec/output/\n"
     ]
    }
   ],
   "source": [
    "## Input data bucket and prefix\n",
    "\n",
    "bucket = 'aws-ml-chicago-team-bravesouls' # Customize your bucket\n",
    "prefix = 'object2vec/input/' \n",
    "input_path = os.path.join('s3://', bucket, prefix)\n",
    "print(f\"Data path for training is {input_path}\")\n",
    "## Output path\n",
    "output_prefix = 'object2vec/output/'\n",
    "output_bucket = bucket\n",
    "output_path = os.path.join('s3://', output_bucket, output_prefix)\n",
    "print(f\"Trained model will be saved at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::023375022819:role/service-role/AmazonSageMaker-ExecutionRole-20181029T121824\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "## Get docker image of ObjectToVec algorithm\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'object2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import s3_input\n",
    "\n",
    "\n",
    "def set_training_environment(bucket, prefix, base_hyperparameters=DEFAULT_HP,\n",
    "                             is_quick_run=True, is_pretrain=False, use_all_vocab=False):\n",
    "    \n",
    "    input_channels = {}\n",
    "    s3_client = boto3.client('s3')\n",
    "    for split in ['train', 'validation']:\n",
    "        if is_pretrain:\n",
    "            fname_in = f'all_vocab_datasets/snli-integer-{split}-pretrain.jsonl'\n",
    "            fname_out = f'{split}/snli-integer-{split}-pretrain.jsonl'\n",
    "        else:\n",
    "            fname_in = os.path.join(SNLI_PATH, f'snli-integer-{split}-.jsonl')\n",
    "            fname_out = f'{split}/snli-integer-{split}.jsonl'\n",
    "        \n",
    "        s3_client.upload_file(fname_in, bucket, os.path.join(prefix, fname_out))\n",
    "        input_channels[split] = s3_input(input_path + fname_out, \n",
    "                                 distribution='ShardedByS3Key', \n",
    "                                 content_type='application/jsonlines')\n",
    "    \n",
    "        print('Uploaded {} data to {}'.format(split, input_path + fname_out))\n",
    "    \n",
    "    hyperparameters = base_hyperparameters.copy()\n",
    "    \n",
    "    if use_all_vocab:\n",
    "        hyperparameters['enc0_vocab_file'] = 'all_vocab.json'\n",
    "        hyperparameters['enc1_vocab_file'] = 'all_vocab.json'\n",
    "        hyperparameters['enc0_vocab_size'] = 43662\n",
    "        hyperparameters['enc1_vocab_size'] = 43662\n",
    "\n",
    "    if is_pretrain:\n",
    "        ## set up auxliary channel\n",
    "        aux_path = os.path.join(prefix, \"auxiliary\")\n",
    "        # upload auxiliary files\n",
    "        assert os.path.exists(\"GloVe/glove.840B-trim.txt\"), \"Pretrained embedding does not exist!\"\n",
    "        s3_client.upload_file(\"GloVe/glove.840B-trim.txt\", bucket, os.path.join(aux_path, 'glove.840B-trim.txt'))\n",
    "        if use_all_vocab:\n",
    "            s3_client.upload_file('all_vocab_datasets/all_vocab.json', \n",
    "                                  bucket, os.path.join(aux_path, 'all_vocab.json'))\n",
    "        else:\n",
    "            s3_client.upload_file(\"snli_1.0/snli-vocab.json\", \n",
    "                                  bucket, os.path.join(aux_path, \"snli-vocab.json\"))\n",
    "\n",
    "        input_channels['auxiliary'] = s3_input('s3://' + bucket + '/' + aux_path, \n",
    "                                     distribution='FullyReplicated', content_type='application/json')\n",
    "        \n",
    "        print('Uploaded auxiliary data for initializing with pretrain-embedding to {}'.format(aux_path))\n",
    "        \n",
    "        # add pretrained_embedding_file name to hyperparameters\n",
    "        for idx in [0, 1]:\n",
    "            hyperparameters[f'enc{idx}_pretrained_embedding_file'] = 'glove.840B-trim.txt'\n",
    "\n",
    "    if is_quick_run:\n",
    "        hyperparameters['mini_batch_size'] = 8192\n",
    "        hyperparameters['enc_dim'] = 16\n",
    "        hyperparameters['epochs'] = 20\n",
    "    else:\n",
    "        hyperparameters['mini_batch_size'] = 256\n",
    "        hyperparameters['enc_dim'] = 8192\n",
    "        hyperparameters['epochs'] = 20\n",
    "    return hyperparameters, input_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded train data to s3://aws-ml-chicago-team-bravesouls/object2vec/input/train/snli-integer-train.jsonl\n",
      "Uploaded validation data to s3://aws-ml-chicago-team-bravesouls/object2vec/input/validation/snli-integer-validation.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'enc_dim': 16,\n",
       " 'mlp_dim': 512,\n",
       " 'mlp_activation': 'linear',\n",
       " 'mlp_layers': 2,\n",
       " 'output_layer': 'softmax',\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.0004,\n",
       " 'mini_batch_size': 8192,\n",
       " 'epochs': 20,\n",
       " 'bucket_width': 0,\n",
       " 'early_stopping_tolerance': 0.01,\n",
       " 'early_stopping_patience': 3,\n",
       " 'dropout': 0,\n",
       " 'weight_decay': 0,\n",
       " 'enc0_max_seq_len': 82,\n",
       " 'enc1_max_seq_len': 82,\n",
       " 'enc0_network': 'hcnn',\n",
       " 'enc1_network': 'enc0',\n",
       " 'enc0_token_embedding_dim': 300,\n",
       " 'enc0_layers': 'auto',\n",
       " 'enc0_cnn_filter_width': 3,\n",
       " 'enc1_token_embedding_dim': 300,\n",
       " 'enc1_layers': 'auto',\n",
       " 'enc1_cnn_filter_width': 3,\n",
       " 'enc0_vocab_file': '',\n",
       " 'enc1_vocab_file': '',\n",
       " 'enc0_vocab_size': 43533,\n",
       " 'enc1_vocab_size': 43533,\n",
       " 'num_classes': 3,\n",
       " '_num_gpus': 'auto',\n",
       " '_num_kv_servers': 'auto',\n",
       " '_kvstore': 'device'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get estimator\n",
    "regressor = sagemaker.estimator.Estimator(container,\n",
    "                                          role, \n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.p2.xlarge',\n",
    "                                          output_path=output_path,\n",
    "                                          sagemaker_session=sess)\n",
    "\n",
    "\n",
    "## set up training environment\n",
    "\"\"\"\n",
    "- To get good training result, set is_quick_run to False \n",
    "- To test-run the algorithm quickly, set is_quick_run to True\n",
    "\"\"\"\n",
    "hyperparameters, input_channels = set_training_environment(bucket, prefix, \n",
    "                                                           is_quick_run=True, \n",
    "                                                           is_pretrain=False, use_all_vocab=False)\n",
    "\n",
    "regressor.set_hyperparameters(**hyperparameters)\n",
    "regressor.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: object2vec-2019-01-10-05-58-53-308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-10 05:58:53 Starting - Starting the training job...\n",
      "2019-01-10 05:58:55 Starting - Launching requested ML instances......\n",
      "2019-01-10 06:00:02 Starting - Preparing the instances for training......\n",
      "2019-01-10 06:01:21 Downloading - Downloading input data...\n",
      "2019-01-10 06:01:35 Training - Downloading the training image..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': 20, u'mlp_dim': 512, u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': 2, u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_token_embedding_dim': 300, u'enc1_network': u'enc0', u'learning_rate': 0.0004, u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': 3, u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': 0.01, u'dropout': 0, u'bucket_width': 0, u'enc_dim': 4096, u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': 32, u'enc1_pretrained_embedding_file': u'', u'num_classes': 2, u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'enc1_token_embedding_dim': 300, u'_kvstore': u'auto_gpu'}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'512', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'mini_batch_size': u'8192', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'enc0', u'learning_rate': u'0.0004', u'early_stopping_tolerance': u'0.01', u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'82', u'enc1_cnn_filter_width': u'3', u'dropout': u'0', u'bucket_width': u'0', u'enc_dim': u'16', u'enc0_layers': u'auto', u'enc0_max_seq_len': u'82', u'num_classes': u'3', u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'43533', u'enc0_vocab_size': u'43533'}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Final configuration: {u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'82', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'enc0', u'learning_rate': u'0.0004', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'82', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0', u'bucket_width': u'0', u'enc_dim': u'16', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'8192', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'3', u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'43533', u'enc0_vocab_size': u'43533'}\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Using default worker.\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] create_iter params {u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'82', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'enc0', u'learning_rate': u'0.0004', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'82', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0', u'bucket_width': u'0', u'enc_dim': u'16', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'8192', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'3', u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'43533', u'enc0_vocab_size': u'43533'}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'43533', u'network': u'hcnn', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'82', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'43533', u'network': u'enc0', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'82', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Encoder configs: [{'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 0, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 1, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Config: {'epochs': 20, 'mini_batch_size': 8192, 'optimizer': 'adam', 'output_layer': 'softmax', 'mlp_dim': 512, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 16, 'early_stopping_patience': 3, 'learning_rate': 0.0004, 'max_seq_lens': [82, 82], 'enc_configs': [{'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 0, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 1, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 2, 'weight_decay': 0.0, 'mlp_activation': 'linear', 'num_classes': 3}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] use bucketing: False\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:05 INFO 140672066094912] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\n",
      "2019-01-10 06:02:02 Training - Training image download completed. Training in progress.\u001b[31m[01/10/2019 06:02:30 INFO 140672066094912] Source words: 7706882\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:30 INFO 140672066094912] Target words: 4532953\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:30 INFO 140672066094912] Total: 549367 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:30 INFO 140672066094912] Bucket of (82, 82) : 549367 samples in 67 batches of 8192, approx 65536.0 words/batch\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:30 INFO 140672066094912] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:30 INFO 140672066094912] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:30 INFO 140672066094912] \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:31 INFO 140672066094912] Replicating 7689 random sentences from bucket (82, 82) to size it to multiple of 8192\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Bucket batch sizes: [BucketBatchSize(batch_size=8192, average_words_per_batch=65536)]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] create_iter params {u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'82', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'enc0', u'learning_rate': u'0.0004', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'82', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0', u'bucket_width': u'0', u'enc_dim': u'16', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'8192', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'3', u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'43533', u'enc0_vocab_size': u'43533'}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'43533', u'network': u'hcnn', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'82', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'43533', u'network': u'enc0', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'82', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Encoder configs: [{'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 0, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 1, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Config: {'epochs': 20, 'mini_batch_size': 8192, 'optimizer': 'adam', 'output_layer': 'softmax', 'mlp_dim': 512, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 16, 'early_stopping_patience': 3, 'learning_rate': 0.0004, 'max_seq_lens': [82, 82], 'enc_configs': [{'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 0, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 1, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 2, 'weight_decay': 0.0, 'mlp_activation': 'linear', 'num_classes': 3}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] use bucketing: False\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Source words: 149450\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Target words: 82208\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Total: 9842 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Bucket of (82, 82) : 9842 samples in 1 batches of 8192, approx 65536.0 words/batch\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Replicating 6542 random sentences from bucket (82, 82) to size it to multiple of 8192\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'43533', u'network': u'hcnn', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'82', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'43533', u'network': u'enc0', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'82', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Encoder configs: [{'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 0, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 1, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Config: {'epochs': 20, 'mini_batch_size': 8192, 'optimizer': 'adam', 'output_layer': 'softmax', 'mlp_dim': 512, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 16, 'early_stopping_patience': 3, 'learning_rate': 0.0004, 'max_seq_lens': [82, 82], 'enc_configs': [{'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 0, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 43533, 'pretrained_embedding_file_path': None, 'enc_index': 1, 'cnn_filter_width': 3, 'vocab_dict': None, 'num_layers': 4, 'token_embedding_dim': 300, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'dropout_conv': 0.0, 'num_filters': 4, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 2, 'weight_decay': 0.0, 'mlp_activation': 'linear', 'num_classes': 3}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Creating new state\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] params {u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'512', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'2', u'_num_kv_servers': u'auto', u'weight_decay': u'0', u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'82', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'enc0', u'learning_rate': u'0.0004', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'82', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': u'0', u'bucket_width': u'0', u'enc_dim': u'16', 'default_bucket_key': (82, 82), u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'8192', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'3', u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'43533', u'enc0_vocab_size': u'43533'}\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] default_bucket_key (82, 82)\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] nvidia-smi took: 0.025181055069 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] context [gpu(0)]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Create Store: device\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31msource(null)                                        82                      0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_0(Embedding)                                  82x300                  0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar0(_not_equal_scalar)               82                      0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape0(Reshape)                                   82x1                    0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul0(broadcast_mul)                       82x300                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mswapaxis0(SwapAxis)                                 300x82                  0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msource_0(Convolution)                               4x82                    3604        swapaxis0                       \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation0(Activation)                             4x82                    0           source_0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax0(max)                                           4                       0           activation0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout0(Dropout)                                   4x82                    0           activation0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msource_1(Convolution)                               4x82                    52          dropout0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation1(Activation)                             4x82                    0           source_1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax1(max)                                           4                       0           activation1                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout1(Dropout)                                   4x82                    0           activation1                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msource_2(Convolution)                               4x82                    52          dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation2(Activation)                             4x82                    0           source_2                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax2(max)                                           4                       0           activation2                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout2(Dropout)                                   4x82                    0           activation2                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msource_3(Convolution)                               4x82                    52          dropout2                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation3(Activation)                             4x82                    0           source_3                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax3(max)                                           4                       0           activation3                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcat0(Concat)                                     16                      0           max0                            \n",
      "                                                                                        max1                            \n",
      "                                                                                        max2                            \n",
      "                                                                                        max3                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_1(Embedding)                                  82x300                  0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar1(_not_equal_scalar)               82                      0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape1(Reshape)                                   82x1                    0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul1(broadcast_mul)                       82x300                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mswapaxis1(SwapAxis)                                 300x82                  0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mtarget_0(Convolution)                               4x82                    3604        swapaxis1                       \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation4(Activation)                             4x82                    0           target_0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax4(max)                                           4                       0           activation4                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout4(Dropout)                                   4x82                    0           activation4                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mtarget_1(Convolution)                               4x82                    52          dropout4                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation5(Activation)                             4x82                    0           target_1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax5(max)                                           4                       0           activation5                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout5(Dropout)                                   4x82                    0           activation5                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mtarget_2(Convolution)                               4x82                    52          dropout5                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation6(Activation)                             4x82                    0           target_2                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax6(max)                                           4                       0           activation6                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout6(Dropout)                                   4x82                    0           activation6                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mtarget_3(Convolution)                               4x82                    52          dropout6                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation7(Activation)                             4x82                    0           target_3                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmax7(max)                                           4                       0           activation7                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcat1(Concat)                                     16                      0           max4                            \n",
      "                                                                                        max5                            \n",
      "                                                                                        max6                            \n",
      "                                                                                        max7                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_mul0(elemwise_mul)                                 16                      0           concat0                         \n",
      "                                                                                        concat1                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_minus0(elemwise_sub)                               16                      0           concat0                         \n",
      "                                                                                        concat1                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mabs0(abs)                                           16                      0           _minus0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcat2(Concat)                                     64                      0           _mul0                           \n",
      "                                                                                        concat0                         \n",
      "                                                                                        concat1                         \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmlp_fc0(FullyConnected)                             512                     33280       concat2                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmlp_fc1(FullyConnected)                             512                     262656      mlp_fc0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31moutput_layer(FullyConnected)                        3                       1539        mlp_fc1                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mout_layer(SoftmaxOutput)                            3                       0           output_layer                    \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 304995\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] data_shapes [DataDesc[source,(8192, 82),<type 'numpy.float32'>,NTC], DataDesc[target,(8192, 82),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] label_shapes [DataDesc[out_layer_label,(8192,),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] fixed_param_names: []\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:32 INFO 140672066094912] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[31m[06:02:37] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201119.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:40 INFO 140672066094912] arg_params keys for module initialization: []\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:02:40 INFO 140672066094912] all params:['target_1_bias', 'source_3_weight', 'target_1_weight', 'mlp_fc0_weight', 'source_0_weight', 'source_3_bias', 'output_layer_weight', 'mlp_fc0_bias', 'output_layer_bias', 'source_2_bias', 'mlp_fc1_bias', 'embed_0_weight', 'target_2_weight', 'target_0_weight', 'target_3_weight', 'source_1_weight', 'mlp_fc1_weight', 'target_2_bias', 'embed_1_weight', 'source_2_weight', 'target_0_bias', 'target_3_bias', 'source_1_bias', 'source_0_bias']\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 7663.91396522522, \"sum\": 7663.91396522522, \"min\": 7663.91396522522}}, \"EndTime\": 1547100160.166907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100125.155685}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1547100160.167097, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100160.167034}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] Completed Epoch: 0, time taken: 0:01:07.389699\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] Epoch 0 Training metrics:   perplexity: 2.585 cross_entropy: 0.950 accuracy: 0.550 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] #quality_metric: host=algo-1, epoch=0, train cross_entropy <loss>=0.949708053294\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] #quality_metric: host=algo-1, epoch=0, train accuracy <score>=0.54950130687\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] Epoch 0 Validation metrics: perplexity: 2.244 cross_entropy: 0.808 accuracy: 0.647 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] #quality_metric: host=algo-1, epoch=0, validation cross_entropy <loss>=0.808074295521\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] #quality_metric: host=algo-1, epoch=0, validation accuracy <score>=0.646545410156\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"early_stop.time\": {\"count\": 1, \"max\": 0.9438991546630859, \"sum\": 0.9438991546630859, \"min\": 0.9438991546630859}, \"update.time\": {\"count\": 1, \"max\": 68003.61490249634, \"sum\": 68003.61490249634, \"min\": 68003.61490249634}}, \"EndTime\": 1547100228.889154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100160.166992}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Total Batches Seen\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Total Records Seen\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1547100228.889408, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 0}, \"StartTime\": 1547100160.885519}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:03:48 INFO 140672066094912] #throughput_metric: host=algo-1, train throughput=8191.51502182 records/second\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] Completed Epoch: 1, time taken: 0:01:07.516504\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] Epoch 1 Training metrics:   perplexity: 2.185 cross_entropy: 0.782 accuracy: 0.659 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] #quality_metric: host=algo-1, epoch=1, train cross_entropy <loss>=0.7818309393\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] #quality_metric: host=algo-1, epoch=1, train accuracy <score>=0.65911506204\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] Epoch 1 Validation metrics: perplexity: 2.171 cross_entropy: 0.775 accuracy: 0.660 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] #quality_metric: host=algo-1, epoch=1, validation cross_entropy <loss>=0.775012075901\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] #quality_metric: host=algo-1, epoch=1, validation accuracy <score>=0.659973144531\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 10.397911071777344, \"sum\": 10.397911071777344, \"min\": 10.397911071777344}, \"update.time\": {\"count\": 1, \"max\": 68129.93717193604, \"sum\": 68129.93717193604, \"min\": 68129.93717193604}}, \"EndTime\": 1547100297.798118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100228.889228}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Total Batches Seen\": {\"count\": 1, \"max\": 136, \"sum\": 136.0, \"min\": 136}, \"Total Records Seen\": {\"count\": 1, \"max\": 1114112, \"sum\": 1114112.0, \"min\": 1114112}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1547100297.798391, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 1}, \"StartTime\": 1547100229.668162}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:04:57 INFO 140672066094912] #throughput_metric: host=algo-1, train throughput=8176.32540203 records/second\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] Completed Epoch: 2, time taken: 0:01:07.496125\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] Epoch 2 Training metrics:   perplexity: 2.076 cross_entropy: 0.731 accuracy: 0.686 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] #quality_metric: host=algo-1, epoch=2, train cross_entropy <loss>=0.730675814783\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] #quality_metric: host=algo-1, epoch=2, train accuracy <score>=0.685855641085\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] Epoch 2 Validation metrics: perplexity: 2.168 cross_entropy: 0.774 accuracy: 0.663 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] #quality_metric: host=algo-1, epoch=2, validation cross_entropy <loss>=0.773631125689\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] #quality_metric: host=algo-1, epoch=2, validation accuracy <score>=0.663269042969\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 14.91999626159668, \"sum\": 14.91999626159668, \"min\": 14.91999626159668}, \"update.time\": {\"count\": 1, \"max\": 68119.28796768188, \"sum\": 68119.28796768188, \"min\": 68119.28796768188}}, \"EndTime\": 1547100366.659765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100297.798193}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Total Batches Seen\": {\"count\": 1, \"max\": 204, \"sum\": 204.0, \"min\": 204}, \"Total Records Seen\": {\"count\": 1, \"max\": 1671168, \"sum\": 1671168.0, \"min\": 1671168}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1547100366.660085, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 2}, \"StartTime\": 1547100298.540451}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:06:06 INFO 140672066094912] #throughput_metric: host=algo-1, train throughput=8177.59494063 records/second\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:14 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:14 INFO 140672066094912] Completed Epoch: 3, time taken: 0:01:07.501207\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:14 INFO 140672066094912] Epoch 3 Training metrics:   perplexity: 2.015 cross_entropy: 0.700 accuracy: 0.701 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:14 INFO 140672066094912] #quality_metric: host=algo-1, epoch=3, train cross_entropy <loss>=0.70049722931\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:14 INFO 140672066094912] #quality_metric: host=algo-1, epoch=3, train accuracy <score>=0.701446533203\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] Epoch 3 Validation metrics: perplexity: 2.175 cross_entropy: 0.777 accuracy: 0.663 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] #quality_metric: host=algo-1, epoch=3, validation cross_entropy <loss>=0.777005851269\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] #quality_metric: host=algo-1, epoch=3, validation accuracy <score>=0.6630859375\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] patience losses: [0.80807429552078247, 0.77501207590103149, 0.77363112568855286]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] min patience losses: 0.773631125689\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] current loss: 0.777005851269\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] absolute loss difference: 0.00337472558022\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.5090236663818359, \"sum\": 0.5090236663818359, \"min\": 0.5090236663818359}, \"update.time\": {\"count\": 1, \"max\": 68110.52894592285, \"sum\": 68110.52894592285, \"min\": 68110.52894592285}}, \"EndTime\": 1547100435.532321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100366.659874}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Total Batches Seen\": {\"count\": 1, \"max\": 272, \"sum\": 272.0, \"min\": 272}, \"Total Records Seen\": {\"count\": 1, \"max\": 2228224, \"sum\": 2228224.0, \"min\": 2228224}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1547100435.532608, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 3}, \"StartTime\": 1547100367.421766}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:07:15 INFO 140672066094912] #throughput_metric: host=algo-1, train throughput=8178.64379561 records/second\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[01/10/2019 06:08:23 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:23 INFO 140672066094912] Completed Epoch: 4, time taken: 0:01:07.491277\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:23 INFO 140672066094912] Epoch 4 Training metrics:   perplexity: 1.972 cross_entropy: 0.679 accuracy: 0.712 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:23 INFO 140672066094912] #quality_metric: host=algo-1, epoch=4, train cross_entropy <loss>=0.678942636532\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:23 INFO 140672066094912] #quality_metric: host=algo-1, epoch=4, train accuracy <score>=0.712007410386\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] Epoch 4 Validation metrics: perplexity: 2.174 cross_entropy: 0.777 accuracy: 0.670 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] #quality_metric: host=algo-1, epoch=4, validation cross_entropy <loss>=0.776619881392\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] #quality_metric: host=algo-1, epoch=4, validation accuracy <score>=0.669799804688\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] patience losses: [0.77501207590103149, 0.77363112568855286, 0.77700585126876831]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] min patience losses: 0.773631125689\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] current loss: 0.776619881392\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] absolute loss difference: 0.00298875570297\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.46515464782714844, \"sum\": 0.46515464782714844, \"min\": 0.46515464782714844}, \"update.time\": {\"count\": 1, \"max\": 68097.87797927856, \"sum\": 68097.87797927856, \"min\": 68097.87797927856}}, \"EndTime\": 1547100504.271483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100435.532423}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Total Batches Seen\": {\"count\": 1, \"max\": 340, \"sum\": 340.0, \"min\": 340}, \"Total Records Seen\": {\"count\": 1, \"max\": 2785280, \"sum\": 2785280.0, \"min\": 2785280}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1547100504.271736, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 4}, \"StartTime\": 1547100436.173578}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:08:24 INFO 140672066094912] #throughput_metric: host=algo-1, train throughput=8180.17363502 records/second\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:32 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:32 INFO 140672066094912] Completed Epoch: 5, time taken: 0:01:07.592453\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:32 INFO 140672066094912] Epoch 5 Training metrics:   perplexity: 1.938 cross_entropy: 0.661 accuracy: 0.720 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:32 INFO 140672066094912] #quality_metric: host=algo-1, epoch=5, train cross_entropy <loss>=0.661431920879\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:32 INFO 140672066094912] #quality_metric: host=algo-1, epoch=5, train accuracy <score>=0.720390768612\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] Epoch 5 Validation metrics: perplexity: 2.186 cross_entropy: 0.782 accuracy: 0.672 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] #quality_metric: host=algo-1, epoch=5, validation cross_entropy <loss>=0.782227069139\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] #quality_metric: host=algo-1, epoch=5, validation accuracy <score>=0.671630859375\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] patience losses: [0.77363112568855286, 0.77700585126876831, 0.77661988139152527]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] min patience losses: 0.773631125689\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] current loss: 0.782227069139\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] absolute loss difference: 0.00859594345093\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4601478576660156, \"sum\": 0.4601478576660156, \"min\": 0.4601478576660156}, \"update.time\": {\"count\": 1, \"max\": 68199.79000091553, \"sum\": 68199.79000091553, \"min\": 68199.79000091553}}, \"EndTime\": 1547100573.090506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100504.271562}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Total Batches Seen\": {\"count\": 1, \"max\": 408, \"sum\": 408.0, \"min\": 408}, \"Total Records Seen\": {\"count\": 1, \"max\": 3342336, \"sum\": 3342336.0, \"min\": 3342336}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1547100573.090747, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 5}, \"StartTime\": 1547100504.890688}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:09:33 INFO 140672066094912] #throughput_metric: host=algo-1, train throughput=8167.95380479 records/second\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Completed Epoch: 6, time taken: 0:01:07.552475\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Epoch 6 Training metrics:   perplexity: 1.912 cross_entropy: 0.648 accuracy: 0.727 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] #quality_metric: host=algo-1, epoch=6, train cross_entropy <loss>=0.648140519857\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] #quality_metric: host=algo-1, epoch=6, train accuracy <score>=0.726846133961\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Epoch 6 Validation metrics: perplexity: 2.206 cross_entropy: 0.791 accuracy: 0.667 \u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] #quality_metric: host=algo-1, epoch=6, validation cross_entropy <loss>=0.791081249714\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] #quality_metric: host=algo-1, epoch=6, validation accuracy <score>=0.666564941406\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] **************\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] patience losses: [0.77700585126876831, 0.77661988139152527, 0.78222706913948059]\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] min patience losses: 0.776619881392\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] current loss: 0.791081249714\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] absolute loss difference: 0.0144613683224\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Early stopping criterion met! Stopping training at epoch: 6\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.6499290466308594, \"sum\": 0.6499290466308594, \"min\": 0.6499290466308594}, \"update.time\": {\"count\": 1, \"max\": 68161.1680984497, \"sum\": 68161.1680984497, \"min\": 68161.1680984497}}, \"EndTime\": 1547100641.870039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100573.090581}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Total Batches Seen\": {\"count\": 1, \"max\": 476, \"sum\": 476.0, \"min\": 476}, \"Total Records Seen\": {\"count\": 1, \"max\": 3899392, \"sum\": 3899392.0, \"min\": 3899392}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 557056, \"sum\": 557056.0, \"min\": 557056}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1547100641.870395, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 6}, \"StartTime\": 1547100573.708844}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] #throughput_metric: host=algo-1, train throughput=8172.56757518 records/second\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 WARNING 140672066094912] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Best model based on epoch 2. Best loss: 0.774\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2.8820037841796875, \"sum\": 2.8820037841796875, \"min\": 2.8820037841796875}}, \"EndTime\": 1547100641.8736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100641.870133}\n",
      "\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:41 INFO 140672066094912] Saved checkpoint to \"/tmp/tmpaSoiLE/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[01/10/2019 06:10:42 INFO 140672066094912] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 517256.2258243561, \"sum\": 517256.2258243561, \"min\": 517256.2258243561}, \"model.serialize.time\": {\"count\": 1, \"max\": 402.57787704467773, \"sum\": 402.57787704467773, \"min\": 402.57787704467773}, \"setuptime\": {\"count\": 1, \"max\": 61.76280975341797, \"sum\": 61.76280975341797, \"min\": 61.76280975341797}}, \"EndTime\": 1547100642.309327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1547100641.873653}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-01-10 06:10:43 Uploading - Uploading generated training model\n",
      "2019-01-10 06:11:25 Completed - Training job completed\n",
      "Billable seconds: 604\n"
     ]
    }
   ],
   "source": [
    "regressor.fit(input_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "latest_job_name = regressor.latest_training_job.job_name\n",
    "metric_name = 'validation:cross_entropy'\n",
    "\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=latest_job_name, metric_names=[metric_name]).dataframe()\n",
    "plt = metrics_dataframe.plot(kind='line', figsize=(12,5), x='timestamp', y='value', style='b.', legend=False)\n",
    "plt.set_ylabel(metric_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: object2vec-2019-01-10-06-12-08-834\n",
      "INFO:sagemaker:Creating endpoint with name object2vec-2019-01-10-05-58-53-308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "# deploy model and create endpoint and with customer-defined endpoint_name\n",
    "predictor1 = regressor.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encode-decode format for inference data\n",
    "predictor1.content_type = 'application/json'\n",
    "predictor1.serializer = json_serializer\n",
    "predictor1.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prediction_accuracy(predictions, labels):\n",
    "    loss = 0\n",
    "    for idx, s_and_l in enumerate(zip(predictions['predictions'], labels)):\n",
    "        score, label = s_and_l\n",
    "        plabel = np.argmax(score['scores'])\n",
    "        loss += int(plabel != label['label'])\n",
    "    return 1 - loss / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test results on SNLI without pre-trained embedding...\n",
      "Evaluating the 1-th batch\n",
      "Evaluating the 11-th batch\n",
      "Evaluating the 21-th batch\n",
      "Evaluating the 31-th batch\n",
      "Evaluating the 41-th batch\n",
      "Evaluating the 51-th batch\n",
      "Evaluating the 61-th batch\n",
      "Evaluating the 71-th batch\n",
      "Evaluating the 81-th batch\n",
      "Evaluating the 91-th batch\n",
      "The test accuracy is 0.6618359799131378\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sagemaker\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "# load SNLI test data\n",
    "snli_test_path = os.path.join(SNLI_PATH, 'snli-integer-test-.jsonl')\n",
    "test_data_content = list()\n",
    "test_label = list()\n",
    "\n",
    "for line in read_jsonline(snli_test_path):\n",
    "    test_data_content.append({'in0':line['in0'], 'in1':line['in1']})\n",
    "    test_label.append({'label': line['label']})\n",
    "\n",
    "print(\"Evaluating test results on SNLI without pre-trained embedding...\")\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "n_test = len(test_label)\n",
    "n_batches = math.ceil(n_test / float(batch_size))\n",
    "start = 0\n",
    "agg_acc = 0\n",
    "for idx in range(n_batches):\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"Evaluating the {idx+1}-th batch\")\n",
    "    end = (start + batch_size) if (start + batch_size) <= n_test else n_test\n",
    "    payload = {'instances': test_data_content[start:end]}\n",
    "    acc = calc_prediction_accuracy(predictor1.predict(payload), test_label[start:end])\n",
    "    agg_acc += acc * (end-start+1)\n",
    "    start = end\n",
    "print(f\"The test accuracy is {agg_acc/n_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
